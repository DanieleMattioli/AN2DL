{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Networks and Deep Learning: Homework 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We run this code on Kaggle kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\" \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Set the seed for random operations. \n",
    "# This let our experiments to be reproducible. \n",
    "SEED = 1234\n",
    "tf.random.set_seed(SEED)  \n",
    "\n",
    "# Get current working directory\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# Set GPU memory growth\n",
    "# Allows to only as much GPU memory as needed\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we used different values of parameters in data augmentation (wrt the other notebook).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageDataGenerator\n",
    "# ------------------\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "apply_data_augmentation = True\n",
    "\n",
    "\n",
    "# Create training ImageDataGenerator object\n",
    "# We need two different generators for images and corresponding masks\n",
    "if apply_data_augmentation:\n",
    "    train_img_data_gen = ImageDataGenerator(rotation_range=0.2,\n",
    "                                            width_shift_range=0.05,\n",
    "                                            height_shift_range=0.05,\n",
    "                                            shear_range=0.05,\n",
    "                                            zoom_range=0.05,\n",
    "                                            horizontal_flip=True,\n",
    "                                            vertical_flip=True,\n",
    "                                            fill_mode='nearest',\n",
    "                                            cval=0,\n",
    "                                            rescale=1./255,\n",
    "                                            validation_split=0.2) #fraction of training images in the validation set \n",
    "    train_mask_data_gen = ImageDataGenerator(rotation_range=0.2,\n",
    "                                             width_shift_range=0.05,\n",
    "                                             height_shift_range=0.05,\n",
    "                                             shear_range=0.05,\n",
    "                                             zoom_range=0.05,\n",
    "                                             horizontal_flip=True,\n",
    "                                             vertical_flip=True,\n",
    "                                             fill_mode='nearest',\n",
    "                                             cval=0,\n",
    "                                             rescale=1./255, \n",
    "                                             validation_split=0.2)  \n",
    "else:\n",
    "    train_img_data_gen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "    train_mask_data_gen = ImageDataGenerator(rescale=1./255,validation_split=0.2)\n",
    "\n",
    "# Create test ImageDataGenerator object\n",
    "test_img_data_gen = ImageDataGenerator(rescale=1./255)\n",
    "test_mask_data_gen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6118 images belonging to 1 classes.\n",
      "Found 6118 images belonging to 1 classes.\n",
      "Found 1529 images belonging to 1 classes.\n",
      "Found 1529 images belonging to 1 classes.\n",
      "Found 1234 images belonging to 1 classes.\n",
      "/kaggle/input/ann-and-dl-image-segmentation/Segmentation_Dataset/test\n"
     ]
    }
   ],
   "source": [
    "# Create generators to read images from dataset directory\n",
    "# -------------------------------------------------------\n",
    "dataset_dir = os.path.join('/kaggle', 'input')\n",
    "dataset_dir = os.path.join(dataset_dir, 'ann-and-dl-image-segmentation')\n",
    "dataset_dir = os.path.join(dataset_dir, 'Segmentation_Dataset')\n",
    "\n",
    "# Batch size\n",
    "bs = 4\n",
    "\n",
    "# img shape\n",
    "img_h = 256\n",
    "img_w = 256\n",
    "\n",
    "num_classes=2\n",
    "\n",
    "# Training\n",
    "# Two different generators for images and masks\n",
    "# ATTENTION: here the seed is important!! We have to give the same SEED to both the generator\n",
    "# to apply the same transformations/shuffling to images and corresponding masks\n",
    "training_dir = os.path.join(dataset_dir, 'training')\n",
    "train_img_gen = train_img_data_gen.flow_from_directory(os.path.join(training_dir, 'images'),\n",
    "                                                       target_size=(img_h, img_w),\n",
    "                                                       batch_size=bs, \n",
    "                                                       class_mode=None, # Because we have no class subfolders in this case\n",
    "                                                       shuffle=True,\n",
    "                                                       interpolation='bilinear',\n",
    "                                                       seed=SEED,\n",
    "                                                       subset='training')  # set as training data\n",
    "train_mask_gen = train_mask_data_gen.flow_from_directory(os.path.join(training_dir, 'masks'),\n",
    "                                                         target_size=(img_h, img_w),\n",
    "                                                         batch_size=bs,\n",
    "                                                         class_mode=None, # Because we have no class subfolders in this case\n",
    "                                                         shuffle=True,\n",
    "                                                         interpolation='bilinear',\n",
    "                                                         seed=SEED,\n",
    "                                                         subset='training',    # set as training data\n",
    "                                                         color_mode='grayscale')  \n",
    "train_gen = zip(train_img_gen, train_mask_gen)\n",
    "\n",
    "# Validation\n",
    "valid_img_gen = train_img_data_gen.flow_from_directory(os.path.join(training_dir, 'images'),\n",
    "                                                       target_size=(img_h, img_w),\n",
    "                                                       batch_size=bs, \n",
    "                                                       class_mode=None, # Because we have no class subfolders in this case\n",
    "                                                       shuffle=False,\n",
    "                                                       interpolation='bilinear',\n",
    "                                                       seed=SEED,\n",
    "                                                       subset='validation')   # set as validation data\n",
    "valid_mask_gen = train_mask_data_gen.flow_from_directory(os.path.join(training_dir, 'masks'),\n",
    "                                                         target_size=(img_h, img_w),\n",
    "                                                         batch_size=bs, \n",
    "                                                         class_mode=None, # Because we have no class subfolders in this case\n",
    "                                                         shuffle=False,\n",
    "                                                         interpolation='bilinear',\n",
    "                                                         seed=SEED,\n",
    "                                                         subset='validation',   # set as validation data\n",
    "                                                         color_mode='grayscale')  \n",
    "valid_gen = zip(valid_img_gen, valid_mask_gen)\n",
    "\n",
    "# Test\n",
    "test_dir = os.path.join(dataset_dir, 'test')\n",
    "test_img_gen = test_img_data_gen.flow_from_directory(os.path.join(test_dir, 'images'),\n",
    "                                                     target_size=(img_h, img_w),\n",
    "                                                     batch_size=bs, \n",
    "                                                     class_mode=None, # Because we have no class subfolders in this case\n",
    "                                                     shuffle=False,\n",
    "                                                     interpolation='bilinear',\n",
    "                                                     seed=SEED)\n",
    "\n",
    "test_gen = test_img_gen\n",
    "print(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset objects\n",
    "# ----------------------\n",
    "\n",
    "# Training\n",
    "# --------\n",
    "train_dataset = tf.data.Dataset.from_generator(lambda: train_gen,\n",
    "                                               output_types=(tf.float32, tf.float32),\n",
    "                                               output_shapes=([None, img_h, img_w, 3], [None, img_h, img_w, 1]))\n",
    "\n",
    "def prepare_target(x_, y_):\n",
    "    y_ = tf.cast(y_, tf.int32)\n",
    "    return x_, y_\n",
    "\n",
    "train_dataset = train_dataset.map(prepare_target)\n",
    "\n",
    "# Repeat\n",
    "train_dataset = train_dataset.repeat()\n",
    "\n",
    "# Validation\n",
    "# ----------\n",
    "valid_dataset = tf.data.Dataset.from_generator(lambda: valid_gen, \n",
    "                                               output_types=(tf.float32, tf.float32),\n",
    "                                               output_shapes=([None, img_h, img_w, 3], [None, img_h, img_w, 1]))\n",
    "valid_dataset = valid_dataset.map(prepare_target)\n",
    "\n",
    "# Repeat\n",
    "valid_dataset = valid_dataset.repeat()\n",
    "\n",
    "# Test\n",
    "# ----\n",
    "test_dataset = tf.data.Dataset.from_generator(lambda: test_gen,\n",
    "                                              output_types=(tf.float32, tf.float32),\n",
    "                                              output_shapes=([None, img_h, img_w, 3], [None, img_h, img_w, 1]))\n",
    "test_dataset = test_dataset.map(prepare_target)\n",
    "\n",
    "# Repeat\n",
    "test_dataset = valid_dataset.repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_IoU(y_true, y_pred):\n",
    "    # from pobability to predicted class {0, 1}\n",
    "    y_pred = tf.cast(y_pred > 0.5, tf.float32) # when using sigmoid. Use argmax for softmax\n",
    "\n",
    "    # A and B\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    # A or B\n",
    "    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - intersection\n",
    "    # IoU\n",
    "    return intersection / union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import os\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "import numpy as np\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet(pretrained_weights = None,input_size = (256,256,3)):\n",
    "    inputs = Input(input_size)\n",
    "    conv1 = Conv2D(64, 5, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv1 = Conv2D(64, 5, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(128, 5, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = Conv2D(128, 5, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    drop4 = Dropout(0.2)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    drop5 = Dropout(0.2)(conv5)\n",
    "\n",
    "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "    merge6 = concatenate([drop4,up6], axis = 3)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = Conv2D(128, 5, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8 = Conv2D(128, 5, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    conv9 = Conv2D(64, 5, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9 = Conv2D(64, 5, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9 = Conv2D(2, 5, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "    model = Model(input = inputs, output = conv10)\n",
    "\n",
    "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = [my_IoU]) #['accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "\n",
    "    if(pretrained_weights):\n",
    "    \tmodel.load_weights(pretrained_weights)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We tried to change the parameters of this model. In particular we changed the number of filters, the size of the kernels and the dropout probability. We obtained the highest score on Kaggle (0.49967) with the parameters of the following model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet(pretrained_weights = None,input_size = (256,256,3)):\n",
    "    inputs = Input(input_size)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    drop1 = Dropout(0.3)(pool1)\n",
    "    \n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(drop1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    drop4 = Dropout(0.3)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    drop5 = Dropout(0.3)(conv5)\n",
    "\n",
    "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "    merge6 = concatenate([drop4,up6], axis = 3)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "    \n",
    "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "    \n",
    "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    \n",
    "    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "    model = Model(input = inputs, output = conv10)\n",
    "\n",
    "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = [my_IoU]) #['accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "\n",
    "    if(pretrained_weights):\n",
    "     model.load_weights(pretrained_weights)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 256, 256, 64) 4864        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 256, 256, 64) 102464      conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 64) 0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 128, 128, 128 204928      max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 128, 128, 128 409728      conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 128)  0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 64, 64, 256)  295168      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 256)  590080      conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 256)  0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 512)  1180160     max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 512)  2359808     conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32, 32, 512)  0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 16, 16, 512)  0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 1024) 4719616     max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 1024) 9438208     conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 16, 16, 1024) 0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 32, 32, 1024) 0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 512)  2097664     up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 1024) 0           dropout_1[0][0]                  \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 512)  4719104     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 512)  2359808     conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 64, 64, 512)  0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 64, 64, 256)  524544      up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 64, 64, 512)  0           conv2d_6[0][0]                   \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 64, 64, 256)  1179904     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 64, 64, 256)  590080      conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 128, 128, 256 0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 128, 128, 128 131200      up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 128, 128, 256 0           conv2d_4[0][0]                   \n",
      "                                                                 conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 128, 128, 128 819328      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 128, 128, 128 409728      conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 256, 256, 128 0           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 256, 256, 64) 32832       up_sampling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 256, 256, 128 0           conv2d_2[0][0]                   \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 256, 256, 64) 204864      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 256, 256, 64) 102464      conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 256, 256, 2)  3202        conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 256, 256, 1)  3           conv2d_23[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 32,479,749\n",
      "Trainable params: 32,479,749\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:43: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"co...)`\n"
     ]
    }
   ],
   "source": [
    "model = unet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1530/1530 [==============================] - 534s 349ms/step - loss: 0.5067 - my_IoU: 0.3360 - val_loss: 0.3488 - val_my_IoU: 0.4420\n",
      "Epoch 2/150\n",
      "1530/1530 [==============================] - 521s 340ms/step - loss: 0.4027 - my_IoU: 0.5151 - val_loss: 0.2741 - val_my_IoU: 0.4325\n",
      "Epoch 3/150\n",
      "1530/1530 [==============================] - 521s 340ms/step - loss: 0.3525 - my_IoU: 0.5819 - val_loss: 0.2547 - val_my_IoU: 0.5442\n",
      "Epoch 4/150\n",
      "1530/1530 [==============================] - 531s 347ms/step - loss: 0.3251 - my_IoU: 0.6169 - val_loss: 0.2280 - val_my_IoU: 0.5886\n",
      "Epoch 5/150\n",
      "1530/1530 [==============================] - 517s 338ms/step - loss: 0.3039 - my_IoU: 0.6436 - val_loss: 0.2369 - val_my_IoU: 0.6220\n",
      "Epoch 6/150\n",
      "1530/1530 [==============================] - 517s 338ms/step - loss: 0.2908 - my_IoU: 0.6623 - val_loss: 0.2042 - val_my_IoU: 0.6311\n",
      "Epoch 7/150\n",
      "1530/1530 [==============================] - 519s 339ms/step - loss: 0.2713 - my_IoU: 0.6827 - val_loss: 0.2177 - val_my_IoU: 0.6476\n",
      "Epoch 8/150\n",
      "1529/1530 [============================>.] - ETA: 0s - loss: 0.2658 - my_IoU: 0.6900"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# from tensorflow.compat.v1 import ConfigProto\n",
    "# from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "# config = ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "# session = InteractiveSession(config=config)\n",
    "\n",
    "cwd = os.getcwd()\n",
    "callbacks = []\n",
    "# Early Stopping\n",
    "# --------------\n",
    "early_stop = True\n",
    "if early_stop:\n",
    "    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_my_IoU', patience=10)\n",
    "    callbacks.append(es_callback)\n",
    "    \n",
    "\n",
    "model.fit_generator(train_gen,\n",
    "                    epochs=150,\n",
    "                    steps_per_epoch=len(train_img_gen),\n",
    "                    validation_data=valid_gen,\n",
    "                    validation_steps=len(valid_img_gen),\n",
    "                    callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just for exercise try to restore a model after training it\n",
    "# !! Use this just when restoring model.. \n",
    "# ---------------------------------------\n",
    "#restore_model = True\n",
    "#if restore_model:\n",
    "#    model = create_model(depth=4, \n",
    "#                         start_f=4, \n",
    "#                         num_classes=3, \n",
    "#                         dynamic_input_shape=True)\n",
    "\n",
    "#    model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), \n",
    "#                  metrics=metrics)  # Needed for loading weights\n",
    "\n",
    "#    model.load_weights(os.path.join(\n",
    "#        cwd, 'segmentation_experiments', 'EXP_FOLDER', 'ckpts', 'cp_60.ckpt'))  # use this if you want to restore saved model\n",
    "# ----------------------------------------\n",
    "\n",
    "eval_out = model.evaluate_generator(valid_gen,\n",
    "                          steps=len(valid_img_gen),\n",
    "                          verbose=0)\n",
    "\n",
    "eval_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We used the function that @LAZCoder shared on Kaggle forum in order to have an idea of our leaderboard score. It takes in input the IoU score and checks if it is greater or not to each threshold used in the evaluation. The output is an approximation of the leaderboard score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_competition_score(score):\n",
    "    thresholds = np.arange(0.5, 1.0, 0.05)\n",
    "    competition_score = 0\n",
    "\n",
    "    for t in thresholds:\n",
    "        if score > t:\n",
    "            competition_score += 1\n",
    "\n",
    "    competition_score /= len(thresholds)\n",
    "\n",
    "    return competition_score\n",
    "print(eval_out[1])\n",
    "calculate_competition_score(eval_out[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def create_csv(results, results_dir='./'):\n",
    "\n",
    "    csv_fname = 'results_'\n",
    "    csv_fname += datetime.now().strftime('%b%d_%H-%M-%S') + '.csv'\n",
    "\n",
    "    with open(csv_fname, 'w') as f:\n",
    "\n",
    "      f.write('ImageId,EncodedPixels,Width,Height\\n')\n",
    "\n",
    "      for key, value in results.items():\n",
    "          f.write(key + ',' + str(value) + ',' + '256' + ',' + '256' + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_encode(img):\n",
    "      # Flatten column-wise\n",
    "      pixels = img.T.flatten()\n",
    "      pixels = np.concatenate([[0], pixels, [0]])\n",
    "      runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "      runs[1::2] -= runs[::2]\n",
    "      return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import data, color\n",
    "from skimage.transform import  resize\n",
    "from skimage.io import imread\n",
    "from skimage.io import imshow\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "path = '/kaggle/input/ann-and-dl-image-segmentation/Segmentation_Dataset/test/images/img'\n",
    "\n",
    "image_filenames = next(os.walk(path))[2]\n",
    "results = {}\n",
    "\n",
    "for img_filename in image_filenames:\n",
    "    new_img_filename = img_filename.replace('.tif','')\n",
    "    img = Image.open(os.path.join(path, img_filename))  \n",
    "    img_arr = np.expand_dims(np.array(img), 0)\n",
    "    \n",
    "    out_softmax = model.predict(x=img_arr/ 255.)\n",
    "    out_softmax[np.where(out_softmax<0.5)] = 0\n",
    "    out_softmax[np.where(out_softmax>=0.5)] = 1\n",
    "\n",
    "    predicted_class = out_softmax       \n",
    "    \n",
    "    results[new_img_filename] = rle_encode(np.array(predicted_class))\n",
    "   \n",
    "create_csv(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
