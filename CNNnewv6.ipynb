{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nimport tensorflow as tf\nimport numpy as np\nfrom datetime import datetime\nfrom PIL import Image\n\n\n\n# line added to solve a warning that tensorflow gave me\ntflogger = tf.get_logger()\ntflogger.setLevel('ERROR')\n# Just disables the warning, doesn't enable AVX/FMA\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n\n# Set the seed for random operations.\n# This let our experiments to be reproducible.\nSEED = 1234\ntf.random.set_seed(SEED)\n\n# Get current working directory\ncwd = os.getcwd() #cwd= /kaggle/working\nprint(cwd)\n# Set GPU memory growth\n# Allows to only as much GPU memory as needed\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n  try:\n    # Currently, memory growth needs to be the same across GPUs\n    for gpu in gpus:\n      tf.config.experimental.set_memory_growth(gpu, True)\n    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n  except RuntimeError as e:\n    # Memory growth must be set before GPUs have been initialized\n    print(e)\n\n# ImageDataGenerator\n# ------------------\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\napply_data_augmentation =True \n\n# Create training ImageDataGenerator object\nif apply_data_augmentation:\n    train_data_gen = ImageDataGenerator(rotation_range=10,\n                                        width_shift_range=10,\n                                        height_shift_range=10,\n                                        zoom_range=0.3,\n                                        horizontal_flip=True,\n                                        vertical_flip=True,\n                                        fill_mode='constant',\n                                        cval=0,\n                                        rescale=1. / 255,\n                                        validation_split=0.2)  # fraction of images reserved for validation\nelse:\n    train_data_gen = ImageDataGenerator(rescale=1. / 255, validation_split=0.2)\n\n# Create test ImageDataGenerator objects (for validation I train_data_gen, since all the images are in the same directory)\ntest_data_gen = ImageDataGenerator(rescale=1. / 255)\n\n# Create generators to read images from dataset directory\n# -------------------------------------------------------\n# dataset_dir = /kaggle/input/Classification_Dataset\ndataset_dir = os.path.join('/kaggle', 'input')\ndataset_dir = os.path.join(dataset_dir, 'classification-dataset/Classification_Dataset')\nprint(dataset_dir)\n# Batch size\n# TODO: ci sono 1554 immagini. 1554 non Ã¨ divisibile per 8. Va bene se metto 7?\nbs = 7\n\n#TODO : probabilmente queste sono da levare\n# img shape\nimg_h = 256\nimg_w = 256\n\nnum_classes = 20\n\ndecide_class_indices = True\nif decide_class_indices:\n    classes = ['owl',               # 0\n               'galaxy',            # 1\n               'lightning',         # 2\n               'wine-bottle',       # 3\n               't-shirt',           # 4\n               'waterfall',         # 5\n               'sword',             # 6\n               'school-bus',        # 7\n               'calculator',        # 8\n               'sheet-music',       # 9\n               'airplanes',         # 10\n               'lightbulb',         # 11\n               'skyscraper',        # 12\n               'mountain-bike',     # 13\n               'fireworks',         # 14\n               'computer-monitor',  # 15\n               'bear',              # 16\n               'grand-piano',       # 17\n               'kangaroo',          # 18\n               'laptop']            # 19\nelse:\n    classes = None\n\n# Training\ntraining_dir = os.path.join(dataset_dir, 'training')\ntrain_gen = train_data_gen.flow_from_directory(training_dir,\n                                               batch_size=bs,\n                                               classes=classes,\n                                               class_mode='categorical',\n                                               shuffle=True,\n                                               seed=SEED,\n                                               subset='training')  # set as training data\n# Validation\nvalid_gen = train_data_gen.flow_from_directory(training_dir,\n                                               batch_size=bs,\n                                               classes=classes,\n                                               class_mode='categorical',\n                                               shuffle=False,\n                                               seed=SEED,\n                                               subset='validation')  # set as validation data\n\n# Test\ntest_dir = os.path.join(dataset_dir, 'test')\ntest_gen = test_data_gen.flow_from_directory(test_dir,\n                                             batch_size=bs,\n                                             classes=classes,\n                                             class_mode='categorical',\n                                             shuffle=False,\n                                             seed=SEED)\n\n# Create Dataset objects\n# ----------------------\n\n# Training\n# create a training set whose elements are generated by the generator train_gen\n# TODO: visto che le immagini sono di dimensione diversa in output_shapes ho messo None al posto che img_h e img_w\ntrain_dataset = tf.data.Dataset.from_generator(lambda: train_gen,\n                                               output_types=(tf.float32, tf.float32),\n                                               output_shapes=([None, img_h, img_w, 3], [None, num_classes])) #TODO: controllare output_shapes\n# Shuffle (Already done in generator..)\n# train_dataset = train_dataset.shuffle(buffer_size=len(train_gen))\n\n# Normalize images (Already done in generator..)\n# def normalize_img(x_, y_):\n#     return tf.cast(x_, tf.float32) / 255., y_\n\n# train_dataset = train_dataset.map(normalize_img)\n\n# 1-hot encoding <- for categorical cross entropy (Already done in generator..)\n# def to_categorical(x_, y_):\n#     return x_, tf.one_hot(y_, depth=10)\n\n# train_dataset = train_dataset.map(to_categorical)\n\n# Divide in batches (Already done in generator..)\n# train_dataset = train_dataset.batch(bs)\n\n# Repeat\n# Without calling the repeat function the dataset\n# will be empty after consuming all the images\ntrain_dataset = train_dataset.repeat()\n\n# Validation\n# ----------\nvalid_dataset = tf.data.Dataset.from_generator(lambda: valid_gen,\n                                               output_types=(tf.float32, tf.float32),\n                                               output_shapes=([None, img_h, img_w, 3], [None, num_classes]))\n\n# Repeat\nvalid_dataset = valid_dataset.repeat()\n# Test\n# ----\ntest_dataset = tf.data.Dataset.from_generator(lambda: test_gen,\n                                              output_types=(tf.float32, tf.float32),\n                                              output_shapes=([None, img_h, img_w, 3], [None, num_classes]))\n\n# Repeat\ntest_dataset = valid_dataset.repeat()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_gen.class_indices","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create Model\n# ------------\nmodel = tf.keras.Sequential()\n#add model layers\nmodel.add(tf.keras.layers.Conv2D(20, kernel_size=(3, 3), strides=(1, 1), activation='relu', input_shape=(img_h,img_w,3)))\nmodel.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\nmodel.add(tf.keras.layers.Conv2D(40, kernel_size=(3, 3), strides=(1, 1), activation='relu'))\nmodel.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\nmodel.add(tf.keras.layers.Conv2D(60, kernel_size=(3, 3), strides=(1, 1), activation='relu'))\nmodel.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\nmodel.add(tf.keras.layers.Conv2D(80, kernel_size=(3, 3), strides=(1, 1), activation='relu'))\nmodel.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\nmodel.add(tf.keras.layers.Flatten())\nmodel.add(tf.keras.layers.Dense(70, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001)))\nmodel.add(tf.keras.layers.Dense(50, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001)))\nmodel.add(tf.keras.layers.Dense(30, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001)))\nmodel.add(tf.keras.layers.Dense(20, activation='softmax', kernel_regularizer=tf.keras.regularizers.l2(0.0001)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualize created model as a table\nmodel.summary()\n# Visualize initialized weights\nprint(model.weights)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rm -r /kaggle/working/classification_experiments","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rm /kaggle/working/results_*","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Optimization params\n# -------------------\n\n# Loss\nloss = tf.keras.losses.CategoricalCrossentropy()\n\n# learning rate\nlr = 1e-3\noptimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n# -------------------\n\n# Validation metrics\n# ------------------\n\nmetrics = ['accuracy']\n# ------------------\n\n# Compile Model\n\nmodel.compile(optimizer=optimizer, loss=loss, metrics=metrics)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from tensorflow.compat.v1 import ConfigProto\n# from tensorflow.compat.v1 import InteractiveSession\n\n# config = ConfigProto()\n# config.gpu_options.allow_growth = True\n# session = InteractiveSession(config=config)\n\ncwd = os.getcwd()\n\nexps_dir = os.path.join(cwd, 'classification_experiments')\nif not os.path.exists(exps_dir):\n    os.makedirs(exps_dir)\n\nnow = datetime.now().strftime('%b%d_%H-%M-%S')\n\nmodel_name = 'CNN'\n\nexp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\nif not os.path.exists(exp_dir):\n    os.makedirs(exp_dir)\n\ncallbacks = []\n\n# Model checkpoint\n# ----------------\nckpt_dir = os.path.join(exp_dir, 'ckpts')\nif not os.path.exists(ckpt_dir):\n    os.makedirs(ckpt_dir)\n\nckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp_{epoch:02d}.ckpt'),\n                                                   save_weights_only=True)  # False to save the model directly\ncallbacks.append(ckpt_callback)\n\n# Visualize Learning on Tensorboard\n# ---------------------------------\ntb_dir = os.path.join(exp_dir, 'tb_logs')\nif not os.path.exists(tb_dir):\n    os.makedirs(tb_dir)\n\n# By default shows losses and metrics for both training and validation\ntb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir,\n                                             profile_batch=0,\n                                             histogram_freq=1)  # if 1 shows weights histograms\ncallbacks.append(tb_callback)\n\n# Early Stopping\n# --------------\nearly_stop = False\nif early_stop:\n    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n    callbacks.append(es_callback)\n\nmodel.fit(x=train_dataset,\n          epochs=100,  #### set repeat in training dataset\n          steps_per_epoch=len(train_gen),\n          validation_data=valid_dataset,\n          validation_steps=len(valid_gen),\n          callbacks=callbacks)\n\n# How to visualize Tensorboard\n\n# 1. tensorboard --logdir EXPERIMENTS_DIR --port PORT     <- from terminal\n# 2. localhost:PORT   <- in your browser\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model.load_weights(\"/kaggle/input\")  # use this if you want to restore saved model\n#model.load_weights(latest)\neval_out = model.evaluate(x=valid_dataset,\n                          steps=len(valid_gen),\n                          verbose=0)\n\nprint(eval_out)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_csv(results, results_dir='./'):\n\n\n    csv_fname = 'results_'\n    csv_fname += datetime.now().strftime('%b%d_%H-%M-%S') + '.csv'\n\n    with open(os.path.join(results_dir, csv_fname), 'w') as f:\n\n        f.write('Id,Category\\n')\n\n        for key, value in results.items():\n            f.write(key + ',' + str(value) + '\\n')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from skimage import data, color\nfrom skimage.transform import  resize\nfrom skimage.io import imread\nfrom skimage.io import imshow\nfrom matplotlib import pyplot as plt\nfrom tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_filenames = next(os.walk(test_dir))[2]\nresults = {}\nfor image_name in tqdm(image_filenames):\n   #img = Image.open(os.path.join(test_dir,image_name)).convert('RGB')\n   img = imread(os.path.join(test_dir,image_name))\n   img = color.gray2rgb(img)\n   img = resize(img, (img_h, img_w))\n   imshow(img)\n   plt.show()\n   img_array = np.array(img) \n   img_array = np.expand_dims(img_array, 0)\n   out_softmax = model.predict(x=img_array)\n   print(\"out_softmax:\")\n   print (out_softmax)\n   prediction = tf.math.argmax(out_softmax, axis=1)   # predicted class\n   print(\"prediction:\")\n   print(prediction[0].numpy())\n   results[image_name] = prediction[0].numpy()\n\ncreate_csv(results)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}