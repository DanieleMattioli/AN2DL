{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Networks and Deep Learning: Homework 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We run this code on Kaggle kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\" \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Set the seed for random operations. \n",
    "# This let our experiments to be reproducible. \n",
    "SEED = 1234\n",
    "tf.random.set_seed(SEED)  \n",
    "\n",
    "# Get current working directory\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# Set GPU memory growth\n",
    "# Allows to only as much GPU memory as needed\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We tried both with and without data augmentation. By using data augmentation results were e bit higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageDataGenerator\n",
    "# ------------------\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "apply_data_augmentation = True\n",
    "\n",
    "# Create training ImageDataGenerator object\n",
    "# We need two different generators for images and corresponding masks\n",
    "if apply_data_augmentation:\n",
    "    train_img_data_gen = ImageDataGenerator(rotation_range=10,\n",
    "                                            width_shift_range=10,\n",
    "                                            height_shift_range=10,\n",
    "                                            zoom_range=0.3,\n",
    "                                            horizontal_flip=True,\n",
    "                                            vertical_flip=True,\n",
    "                                            fill_mode='constant',\n",
    "                                            cval=0,\n",
    "                                            rescale=1./255,\n",
    "                                            validation_split=0.2) #fraction of training images in the validation set \n",
    "    train_mask_data_gen = ImageDataGenerator(rotation_range=10,\n",
    "                                             width_shift_range=10,\n",
    "                                             height_shift_range=10,\n",
    "                                             zoom_range=0.3,\n",
    "                                             horizontal_flip=True,\n",
    "                                             vertical_flip=True,\n",
    "                                             fill_mode='constant',\n",
    "                                             cval=0,\n",
    "                                             rescale=1./255, \n",
    "                                             validation_split=0.2)\n",
    "else:\n",
    "    train_img_data_gen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "    train_mask_data_gen = ImageDataGenerator(rescale=1./255,validation_split=0.2)\n",
    "\n",
    "# Create test ImageDataGenerator object\n",
    "test_img_data_gen = ImageDataGenerator(rescale=1./255)\n",
    "test_mask_data_gen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create generators to read images from dataset directory\n",
    "# -------------------------------------------------------\n",
    "dataset_dir = os.path.join('/kaggle', 'input')\n",
    "dataset_dir = os.path.join(dataset_dir, 'ann-and-dl-image-segmentation')\n",
    "dataset_dir = os.path.join(dataset_dir, 'Segmentation_Dataset')\n",
    "\n",
    "# Batch size\n",
    "bs = 4\n",
    "\n",
    "# img shape\n",
    "img_h = 256\n",
    "img_w = 256\n",
    "\n",
    "num_classes=2\n",
    "\n",
    "# Training\n",
    "# Two different generators for images and masks\n",
    "# ATTENTION: here the seed is important!! We have to give the same SEED to both the generator\n",
    "# to apply the same transformations/shuffling to images and corresponding masks\n",
    "training_dir = os.path.join(dataset_dir, 'training')\n",
    "train_img_gen = train_img_data_gen.flow_from_directory(os.path.join(training_dir, 'images'),\n",
    "                                                       target_size=(img_h, img_w),\n",
    "                                                       batch_size=bs, \n",
    "                                                       class_mode=None, # Because we have no class subfolders in this case\n",
    "                                                       shuffle=True,\n",
    "                                                       interpolation='bilinear',\n",
    "                                                       seed=SEED,\n",
    "                                                       subset='training')  # set as training data\n",
    "train_mask_gen = train_mask_data_gen.flow_from_directory(os.path.join(training_dir, 'masks'),\n",
    "                                                         target_size=(img_h, img_w),\n",
    "                                                         batch_size=bs,\n",
    "                                                         class_mode=None, # Because we have no class subfolders in this case\n",
    "                                                         shuffle=True,\n",
    "                                                         interpolation='bilinear',\n",
    "                                                         seed=SEED,\n",
    "                                                         subset='training',    # set as training data\n",
    "                                                         color_mode='grayscale') \n",
    "train_gen = zip(train_img_gen, train_mask_gen)\n",
    "\n",
    "# Validation\n",
    "valid_img_gen = train_img_data_gen.flow_from_directory(os.path.join(training_dir, 'images'),\n",
    "                                                       target_size=(img_h, img_w),\n",
    "                                                       batch_size=bs, \n",
    "                                                       class_mode=None, # Because we have no class subfolders in this case\n",
    "                                                       shuffle=False,\n",
    "                                                       interpolation='bilinear',\n",
    "                                                       seed=SEED,\n",
    "                                                       subset='validation')   # set as validation data\n",
    "valid_mask_gen = train_mask_data_gen.flow_from_directory(os.path.join(training_dir, 'masks'),\n",
    "                                                         target_size=(img_h, img_w),\n",
    "                                                         batch_size=bs, \n",
    "                                                         class_mode=None, # Because we have no class subfolders in this case\n",
    "                                                         shuffle=False,\n",
    "                                                         interpolation='bilinear',\n",
    "                                                         seed=SEED,\n",
    "                                                         subset='validation', # set as validation data\n",
    "                                                         color_mode='grayscale')  \n",
    "valid_gen = zip(valid_img_gen, valid_mask_gen)\n",
    "\n",
    "# Test\n",
    "test_dir = os.path.join(dataset_dir, 'test')\n",
    "test_img_gen = test_img_data_gen.flow_from_directory(os.path.join(test_dir, 'images'),\n",
    "                                                     target_size=(img_h, img_w),\n",
    "                                                     batch_size=bs, \n",
    "                                                     class_mode=None, # Because we have no class subfolders in this case\n",
    "                                                     shuffle=False,\n",
    "                                                     interpolation='bilinear',\n",
    "                                                     seed=SEED)\n",
    "test_gen = test_img_gen\n",
    "print(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset objects\n",
    "# ----------------------\n",
    "\n",
    "# Training\n",
    "# --------\n",
    "train_dataset = tf.data.Dataset.from_generator(lambda: train_gen,\n",
    "                                               output_types=(tf.float32, tf.float32),\n",
    "                                               output_shapes=([None, img_h, img_w, 3], [None, img_h, img_w, 1])) \n",
    "\n",
    "def prepare_target(x_, y_):\n",
    "    y_ = tf.cast(tf.expand_dims(y_[..., 0], -1), tf.int32)\n",
    "    return x_, y_\n",
    "\n",
    "train_dataset = train_dataset.map(prepare_target)\n",
    "\n",
    "# Repeat\n",
    "train_dataset = train_dataset.repeat()\n",
    "\n",
    "# Validation\n",
    "# ----------\n",
    "valid_dataset = tf.data.Dataset.from_generator(lambda: valid_gen, \n",
    "                                               output_types=(tf.float32, tf.float32),\n",
    "                                               output_shapes=([None, img_h, img_w, 3], [None, img_h, img_w, 1]))\n",
    "valid_dataset = valid_dataset.map(prepare_target)\n",
    "\n",
    "# Repeat\n",
    "valid_dataset = valid_dataset.repeat()\n",
    "\n",
    "# Test\n",
    "# ----\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_generator(lambda: test_gen,\n",
    "                                              output_types=(tf.float32),\n",
    "                                              output_shapes=([None, img_h, img_w, 3]))\n",
    "\n",
    "\n",
    "# Repeat\n",
    "test_dataset = valid_dataset.repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's test data generator\n",
    "# -------------------------\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "fig.show()\n",
    "\n",
    "# Assign a color to each class\n",
    "colors_dict = {}\n",
    "colors_dict[0] = [252, 186, 3]  # foreground\n",
    "colors_dict[1] = [0, 0, 0]  # background\n",
    "colors_dict[2] = [3, 82, 252] # contours\n",
    "\n",
    "iterator = iter(train_dataset)\n",
    "\n",
    "for _ in range(1000):\n",
    "    augmented_img, target = next(iterator)\n",
    "    augmented_img = augmented_img[0]   # First element\n",
    "    augmented_img = augmented_img * 255  # denormalize\n",
    "    \n",
    "    target = np.array(target[0, ..., 0])   # First element (squeezing channel dimension)\n",
    "    \n",
    "    # Assign colors (just for visualization)\n",
    "    target_img = np.zeros([target.shape[0], target.shape[1], 3])\n",
    "    \n",
    "    target_img[np.where(target == 0)] = colors_dict[0]\n",
    "    target_img[np.where(target == 1)] = colors_dict[1]\n",
    "    target_img[np.where(target == 2)] = colors_dict[2]\n",
    "    \n",
    "    ax[0].imshow(np.uint8(augmented_img))\n",
    "    ax[1].imshow(np.uint8(target_img))\n",
    "    \n",
    "    fig.canvas.draw()\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(target_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Model\n",
    "# ------------\n",
    "\n",
    "def create_model(depth, start_f, num_classes, dynamic_input_shape):\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    # Encoder\n",
    "    # -------\n",
    "    for i in range(depth):\n",
    "        \n",
    "        if i == 0:\n",
    "            if dynamic_input_shape:\n",
    "                input_shape = [None, None, 3]\n",
    "            else:\n",
    "                input_shape = [img_h, img_w, 3]\n",
    "        else:\n",
    "            input_shape=[None]\n",
    "        \n",
    "        model.add(tf.keras.layers.Conv2D(filters=start_f, \n",
    "                                         kernel_size=(3, 3),\n",
    "                                         strides=(1, 1),\n",
    "                                         padding='same',\n",
    "                                         input_shape=input_shape))\n",
    "        model.add(tf.keras.layers.ReLU())\n",
    "        model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "        start_f *= 2\n",
    "\n",
    "    # Decoder\n",
    "    # -------\n",
    "    for i in range(depth):\n",
    "        model.add(tf.keras.layers.UpSampling2D(2, interpolation='bilinear'))\n",
    "        model.add(tf.keras.layers.Conv2D(filters=start_f // 2,\n",
    "                                         kernel_size=(3, 3),\n",
    "                                         strides=(1, 1),\n",
    "                                         padding='same'))\n",
    "\n",
    "        model.add(tf.keras.layers.ReLU())\n",
    "\n",
    "        start_f = start_f // 2\n",
    "\n",
    "    # Prediction Layer\n",
    "    # ----------------\n",
    "    model.add(tf.keras.layers.Conv2D(filters=num_classes,\n",
    "                                     kernel_size=(1, 1),\n",
    "                                     strides=(1, 1),\n",
    "                                     padding='same',\n",
    "                                     activation='sigmoid')) #initially it was softmax\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(depth=4, \n",
    "                     start_f=8, \n",
    "                     num_classes=2, \n",
    "                     dynamic_input_shape=False)\n",
    "\n",
    "# Visualize created model as a table\n",
    "model.summary()\n",
    "\n",
    "# Visualize initialized weights\n",
    "model.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We tried to change the parameters of this model. In particular we tried different values of depth, start_f and kernel_size. We also tried to add dropout. With start_f = 8, kernel_size = (5, 5), depth = 4 we got the best score (for this model) on Kaggle and it was  0.32990 (with data augmentation and early stopping).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_IoU(y_true, y_pred):\n",
    "    # from pobability to predicted class {0, 1}\n",
    "    y_pred = tf.cast(y_pred > 0.5, tf.float32) # when using sigmoid. Use argmax for softmax\n",
    "\n",
    "    # A and B\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    # A or B\n",
    "    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - intersection\n",
    "    # IoU\n",
    "    return intersection / union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization params\n",
    "# -------------------\n",
    "\n",
    "# Loss\n",
    "# Sparse Categorical Crossentropy to use integers (mask) instead of one-hot encoded labels\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False) \n",
    "# learning rate\n",
    "lr = 1e-3\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "# -------------------\n",
    "\n",
    "# Validation metrics\n",
    "# ------------------\n",
    "\n",
    "metrics = [my_IoU]\n",
    "# ------------------\n",
    "\n",
    "# Compile Model\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -r /kaggle/working/segmentation_experiments*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# from tensorflow.compat.v1 import ConfigProto\n",
    "# from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "# config = ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "# session = InteractiveSession(config=config)\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "exps_dir = os.path.join(cwd, 'segmentation_experiments')\n",
    "if not os.path.exists(exps_dir):\n",
    "    os.makedirs(exps_dir)\n",
    "\n",
    "now = datetime.now().strftime('%b%d_%H-%M-%S')\n",
    "\n",
    "model_name = 'CNN'\n",
    "\n",
    "exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n",
    "if not os.path.exists(exp_dir):\n",
    "    os.makedirs(exp_dir)\n",
    "    \n",
    "callbacks = []\n",
    "\n",
    "# Model checkpoint\n",
    "# ----------------\n",
    "ckpt_dir = os.path.join(exp_dir, 'ckpts')\n",
    "if not os.path.exists(ckpt_dir):\n",
    "    os.makedirs(ckpt_dir)\n",
    "\n",
    "ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp_{epoch:02d}.ckpt'), \n",
    "                                                   save_weights_only=True)  # False to save the model directly\n",
    "callbacks.append(ckpt_callback)\n",
    "\n",
    "# Visualize Learning on Tensorboard\n",
    "# ---------------------------------\n",
    "tb_dir = os.path.join(exp_dir, 'tb_logs')\n",
    "if not os.path.exists(tb_dir):\n",
    "    os.makedirs(tb_dir)\n",
    "    \n",
    "# By default shows losses and metrics for both training and validation\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir,\n",
    "                                             profile_batch=0,\n",
    "                                             histogram_freq=0)  # if 1 shows weights histograms\n",
    "callbacks.append(tb_callback)\n",
    "\n",
    "# Early Stopping\n",
    "# --------------\n",
    "early_stop = True\n",
    "if early_stop:\n",
    "    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_my_IoU', patience=10)\n",
    "    callbacks.append(es_callback)\n",
    "\n",
    "\n",
    "model.fit(x=train_dataset,\n",
    "          epochs=150,  #### set repeat in training dataset\n",
    "          steps_per_epoch=len(train_img_gen),\n",
    "          validation_data=valid_dataset,\n",
    "          validation_steps=len(valid_img_gen), \n",
    "          callbacks=callbacks)\n",
    "\n",
    "# How to visualize Tensorboard\n",
    "\n",
    "# 1. tensorboard --logdir EXPERIMENTS_DIR --port PORT     <- from terminal\n",
    "# 2. localhost:PORT   <- in your browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just for exercise try to restore a model after training it\n",
    "# !! Use this just when restoring model.. \n",
    "# ---------------------------------------\n",
    "#restore_model = True\n",
    "#if restore_model:\n",
    "#    model = create_model(depth=4, \n",
    "#                         start_f=4, \n",
    "#                         num_classes=3, \n",
    "#                         dynamic_input_shape=True)\n",
    "\n",
    "#    model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), \n",
    "#                  metrics=metrics)  # Needed for loading weights\n",
    "\n",
    "#    model.load_weights(os.path.join(\n",
    "#        cwd, 'segmentation_experiments', 'EXP_FOLDER', 'ckpts', 'cp_60.ckpt'))  # use this if you want to restore saved model\n",
    "# ----------------------------------------\n",
    "\n",
    "eval_out = model.evaluate(x=valid_dataset,\n",
    "                          steps=len(valid_img_gen),\n",
    "                          verbose=0)\n",
    "\n",
    "eval_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We used the function that @LAZCoder shared on Kaggle forum in order to have an idea of our leaderboard score. It takes in input the IoU score and checks if it is greater or not to each threshold used in the evaluation. The output is an approximation of the leaderboard score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_competition_score(score):\n",
    "    thresholds = np.arange(0.5, 1.0, 0.05)\n",
    "    competition_score = 0\n",
    "\n",
    "    for t in thresholds:\n",
    "        if score > t:\n",
    "            competition_score += 1\n",
    "\n",
    "    competition_score /= len(thresholds)\n",
    "\n",
    "    return competition_score\n",
    "print(eval_out[1])\n",
    "calculate_competition_score(eval_out[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def create_csv(results, results_dir='./'):\n",
    "\n",
    "    csv_fname = 'results_'\n",
    "    csv_fname += datetime.now().strftime('%b%d_%H-%M-%S') + '.csv'\n",
    "\n",
    "    with open(csv_fname, 'w') as f:\n",
    "\n",
    "      f.write('ImageId,EncodedPixels,Width,Height\\n')\n",
    "\n",
    "      for key, value in results.items():\n",
    "          f.write(key + ',' + str(value) + ',' + '256' + ',' + '256' + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_encode(img):\n",
    "      # Flatten column-wise\n",
    "      pixels = img.T.flatten()\n",
    "      pixels = np.concatenate([[0], pixels, [0]])\n",
    "      runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "      runs[1::2] -= runs[::2]\n",
    "      return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import data, color\n",
    "from skimage.transform import  resize\n",
    "from skimage.io import imread\n",
    "from skimage.io import imshow\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "path = '/kaggle/input/ann-and-dl-image-segmentation/Segmentation_Dataset/test/images/img'\n",
    "print(path)\n",
    "image_filenames = next(os.walk(path))[2]\n",
    "results = {}\n",
    "\n",
    "for img_filename in image_filenames:\n",
    "    new_img_filename = img_filename.replace('.tif','')\n",
    "    img = Image.open(os.path.join(path, img_filename))  \n",
    "    img_arr = np.expand_dims(np.array(img), 0)\n",
    "    \n",
    "    out_softmax = model.predict(x=img_arr/ 255.)\n",
    "    \n",
    "    # Get predicted class as the index corresponding to the maximum value in the vector probability\n",
    "    predicted_class = tf.argmax(out_softmax, -1)\n",
    "    predicted_class = predicted_class[0]\n",
    "    results[new_img_filename] = rle_encode(np.array(predicted_class))\n",
    "   \n",
    "create_csv(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
